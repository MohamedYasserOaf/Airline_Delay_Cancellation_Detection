{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pyarrow\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "from pyspark.sql.functions import count,isnan,when,col,lit,mean,expr,last,to_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(data, continous_feats ,transformed = False):\n",
    "    \"\"\"\n",
    "    Visualization code for displaying skewed distributions of features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize = (11,5))\n",
    "\n",
    "    # Skewed feature plotting\n",
    "    for i, feature in enumerate(continous_feats):\n",
    "        ax = fig.add_subplot(1, 4, i+1)\n",
    "        ax.hist(data[feature], bins = 25, color = '#00A0A0')\n",
    "        ax.set_title(\"'%s' Feature Distribution\"%(feature), fontsize = 14)\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_ylabel(\"Number of Records\")\n",
    "        ax.set_ylim((0, 2000))\n",
    "        ax.set_yticks([0, 500, 1000, 1500, 2000])\n",
    "        ax.set_yticklabels([0, 500, 1000, 1500, \">2000\"])\n",
    "\n",
    "    # Plot aesthetics\n",
    "    if transformed:\n",
    "        fig.suptitle(\"Log-transformed Distributions of Continuous Census Data Features\", \\\n",
    "            fontsize = 16, y = 1.03)\n",
    "    else:\n",
    "        fig.suptitle(\"Skewed Distributions of Continuous Census Data Features\", \\\n",
    "            fontsize = 16, y = 1.03)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading data and general cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('myAppName') \\\n",
    "    .config('spark.executor.memory', '5gb') \\\n",
    "    .config(\"spark.cores.max\", \"8\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myass\\anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext #sparkcontext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_17 = sqlContext.read.option(\"header\", True).option(\"inferSchema\",True).csv('./Dataset/2017.csv')\n",
    "dataset_18 = sqlContext.read.option(\"header\", True).option(\"inferSchema\",True).csv('./Dataset/2018.csv')\n",
    "dataset = dataset_17.union(dataset_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : 12888067 28\n"
     ]
    }
   ],
   "source": [
    "print(\"shape :\",dataset.count(), len(dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show number of partitions -- > it should be equal to number of cores\n",
    "dataset.rdd.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|2017-01-01|        AA|                1|   JFK| LAX|         800|   831.0|     31.0|    25.0|     856.0|   1143.0|   26.0|        1142|  1209.0|     27.0|      0.0|             null|     0.0|           402.0|              398.0|   347.0|  2475.0|         27.0|          0.0|      0.0|           0.0|                0.0|       null|\n",
      "|2017-01-01|        AA|                2|   LAX| JFK|         900|   934.0|     34.0|    34.0|    1008.0|   1757.0|   12.0|        1727|  1809.0|     42.0|      0.0|             null|     0.0|           327.0|              335.0|   289.0|  2475.0|         34.0|          0.0|      8.0|           0.0|                0.0|       null|\n",
      "|2017-01-01|        AA|                4|   LAX| JFK|        1130|  1221.0|     51.0|    20.0|    1241.0|   2025.0|   15.0|        1958|  2040.0|     42.0|      0.0|             null|     0.0|           328.0|              319.0|   284.0|  2475.0|          7.0|          0.0|      0.0|           0.0|               35.0|       null|\n",
      "|2017-01-01|        AA|                5|   DFW| HNL|        1135|  1252.0|     77.0|    19.0|    1311.0|   1744.0|    5.0|        1612|  1749.0|     97.0|      0.0|             null|     0.0|           517.0|              537.0|   513.0|  3784.0|         77.0|          0.0|     20.0|           0.0|                0.0|       null|\n",
      "|2017-01-01|        AA|                6|   OGG| DFW|        1855|  1855.0|      0.0|    16.0|    1911.0|    631.0|   11.0|         600|   642.0|     42.0|      0.0|             null|     0.0|           425.0|              467.0|   440.0|  3711.0|          0.0|          0.0|     42.0|           0.0|                0.0|       null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FL_DATE', 'string'),\n",
       " ('OP_CARRIER', 'string'),\n",
       " ('OP_CARRIER_FL_NUM', 'int'),\n",
       " ('ORIGIN', 'string'),\n",
       " ('DEST', 'string'),\n",
       " ('CRS_DEP_TIME', 'int'),\n",
       " ('DEP_TIME', 'double'),\n",
       " ('DEP_DELAY', 'double'),\n",
       " ('TAXI_OUT', 'double'),\n",
       " ('WHEELS_OFF', 'double'),\n",
       " ('WHEELS_ON', 'double'),\n",
       " ('TAXI_IN', 'double'),\n",
       " ('CRS_ARR_TIME', 'int'),\n",
       " ('ARR_TIME', 'double'),\n",
       " ('ARR_DELAY', 'double'),\n",
       " ('CANCELLED', 'double'),\n",
       " ('CANCELLATION_CODE', 'string'),\n",
       " ('DIVERTED', 'double'),\n",
       " ('CRS_ELAPSED_TIME', 'double'),\n",
       " ('ACTUAL_ELAPSED_TIME', 'double'),\n",
       " ('AIR_TIME', 'double'),\n",
       " ('DISTANCE', 'double'),\n",
       " ('CARRIER_DELAY', 'double'),\n",
       " ('WEATHER_DELAY', 'double'),\n",
       " ('NAS_DELAY', 'double'),\n",
       " ('SECURITY_DELAY', 'double'),\n",
       " ('LATE_AIRCRAFT_DELAY', 'double'),\n",
       " ('Unnamed: 27', 'string')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop column that all have NA values\n",
    "dataset.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =dataset.drop('Unnamed: 27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'printSchema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12536/3350533299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'printSchema'"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|2017-01-01|        AA|                1|   JFK| LAX|         800|   831.0|     31.0|    25.0|     856.0|   1143.0|   26.0|        1142|  1209.0|     27.0|      0.0|             null|     0.0|           402.0|              398.0|   347.0|  2475.0|         27.0|          0.0|      0.0|           0.0|                0.0|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t =dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|\n",
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|      0|         0|                0|     0|   0|           0|  192625|   197577|  197975|    197970|   203920| 203920|           0|  203919|   232251|        0|         12688790|       0|              17|             229653|  229653|       0|     10505884|     10505884| 10505884|      10505884|           10505884|\n",
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print number of null values for each column\n",
    "amount_missing_df = dataset.select([count(when(col(c).isNull(), c)).alias(c) for c in dataset.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(FL_DATE=0, OP_CARRIER=0, OP_CARRIER_FL_NUM=0, ORIGIN=0, DEST=0, CRS_DEP_TIME=0, DEP_TIME=192625, DEP_DELAY=197577, TAXI_OUT=197975, WHEELS_OFF=197970, WHEELS_ON=203920, TAXI_IN=203920, CRS_ARR_TIME=0, ARR_TIME=203919, ARR_DELAY=232251, CANCELLED=0, CANCELLATION_CODE=12688790, DIVERTED=0, CRS_ELAPSED_TIME=17, ACTUAL_ELAPSED_TIME=229653, AIR_TIME=229653, DISTANCE=0, CARRIER_DELAY=10505884, WEATHER_DELAY=10505884, NAS_DELAY=10505884, SECURITY_DELAY=10505884, LATE_AIRCRAFT_DELAY=10505884)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amount_missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = [\"CARRIER_DELAY\", \"WEATHER_DELAY\", \"NAS_DELAY\", \"SECURITY_DELAY\" ,\"LATE_AIRCRAFT_DELAY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of delay : CARRIER_DELAY\n",
      "# of zeros : 1204800\n",
      "# of zeros percent : 0.5053071521456579\n",
      "mean :  [Row(avg(CARRIER_DELAY)=19.659985399946184)]\n",
      "--------\n",
      "type of delay : WEATHER_DELAY\n",
      "# of zeros : 2247720\n",
      "# of zeros percent : 0.942719946896446\n",
      "mean :  [Row(avg(WEATHER_DELAY)=3.2402355318630014)]\n",
      "--------\n",
      "type of delay : NAS_DELAY\n",
      "# of zeros : 1084689\n",
      "# of zeros percent : 0.4549311998287861\n",
      "mean :  [Row(avg(NAS_DELAY)=15.947230754312326)]\n",
      "--------\n",
      "type of delay : SECURITY_DELAY\n",
      "# of zeros : 2374675\n",
      "# of zeros percent : 0.9959663525244772\n",
      "mean :  [Row(avg(SECURITY_DELAY)=0.09264653471206873)]\n",
      "--------\n",
      "type of delay : LATE_AIRCRAFT_DELAY\n",
      "# of zeros : 1139721\n",
      "# of zeros percent : 0.47801226157918436\n",
      "mean :  [Row(avg(LATE_AIRCRAFT_DELAY)=25.4363867091655)]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# ARR_Delay is the total delay on arrival in minutes , only 1.8% is missing \n",
    "# on the other hand ,  [CARRIER_DELAY WEATHER_DELAY NAS_DELAY SECURITY_DELAY LATE_AIRCRAFT_DELAY] values have 81.5% NA \n",
    "# removing all records with NA values will severely shrink dataset \n",
    "# before we remove all these records , we can try to fill NA values of delay features\n",
    "# we compare number of zeros of a row with total number of records without NA\n",
    "for delay in delays:\n",
    "    print(\"type of delay :\",delay)\n",
    "    print(\"# of zeros :\",dataset.filter(col(delay)==0).count())\n",
    "    print(\"# of zeros percent :\",dataset.filter(col(delay)==0).count()/((18.5/100)*t))\n",
    "    print(\"mean : \",dataset.select(mean(delay)).collect())\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can deduce that number of zeros is dominant in these features , so filling NAs with mean,ffill,backfill,mode or interpolation are not sensible (outliers will increase mean) \n",
    "# best options are zero filling or median(which will probably be 0)\n",
    "dataset = dataset.fillna(0,subset=delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------+--------------+-------------------+\n",
      "|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|\n",
      "+-------------+-------------+---------+--------------+-------------------+\n",
      "|            0|            0|        0|             0|                  0|\n",
      "+-------------+-------------+---------+--------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.select([count(when(col(c).isNull(), c)).alias(c) for c in delays]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|2017-01-01|        AA|                1|   JFK| LAX|         800|   831.0|     31.0|    25.0|     856.0|   1143.0|   26.0|        1142|  1209.0|     27.0|      0.0|             null|     0.0|           402.0|              398.0|   347.0|  2475.0|         27.0|          0.0|      0.0|           0.0|                0.0|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cancellation code - 98% missing and irrelevant\n",
    "dataset =dataset.drop('CANCELLATION_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NAs\n",
    "dataset_visualization = dataset.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : 12651227 26\n"
     ]
    }
   ],
   "source": [
    "#removed around 1.8% of data only\n",
    "print(\"shape :\",dataset_visualization.count(), len(dataset_visualization.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|OP_CARRIER|\n",
      "+----------+\n",
      "|        UA|\n",
      "|        NK|\n",
      "|        AA|\n",
      "|        EV|\n",
      "|        B6|\n",
      "|        DL|\n",
      "|        OO|\n",
      "|        F9|\n",
      "|        HA|\n",
      "|        AS|\n",
      "|        VX|\n",
      "|        WN|\n",
      "|        YV|\n",
      "|        MQ|\n",
      "|        OH|\n",
      "|        G4|\n",
      "|        YX|\n",
      "|        9E|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_visualization.select(\"OP_CARRIER\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myass\\anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py:2233: UserWarning: to_replace is a dict and value is not None. value will be ignored.\n",
      "  warnings.warn(\"to_replace is a dict and value is not None. value will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "#after inspection of op_carriers feature levels , we figured actual carrier names \n",
    "carriers_dict = {\n",
    "    'UA':'United Airlines',\n",
    "    'AS':'Alaska Airlines',\n",
    "    '9E':'Endeavor Air',\n",
    "    'B6':'JetBlue Airways',\n",
    "    'EV':'ExpressJet',\n",
    "    'F9':'Frontier Airlines',\n",
    "    'G4':'Allegiant Air',\n",
    "    'HA':'Hawaiian Airlines',\n",
    "    'MQ':'Envoy Air',\n",
    "    'NK':'Spirit Airlines',\n",
    "    'OH':'PSA Airlines',\n",
    "    'OO':'SkyWest Airlines',\n",
    "    'VX':'Virgin America',\n",
    "    'WN':'Southwest Airlines',\n",
    "    'YV':'Mesa Airline',\n",
    "    'YX':'Republic Airways',\n",
    "    'AA':'American Airlines',\n",
    "    'DL':'Delta Airlines'\n",
    "}\n",
    "dataset_visualization = dataset_visualization.replace(carriers_dict,1,'OP_CARRIER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        OP_CARRIER|\n",
      "+------------------+\n",
      "|   United Airlines|\n",
      "|    Virgin America|\n",
      "| Hawaiian Airlines|\n",
      "|        ExpressJet|\n",
      "|  SkyWest Airlines|\n",
      "| Frontier Airlines|\n",
      "| American Airlines|\n",
      "|   JetBlue Airways|\n",
      "|    Delta Airlines|\n",
      "|   Alaska Airlines|\n",
      "|   Spirit Airlines|\n",
      "|Southwest Airlines|\n",
      "|      Mesa Airline|\n",
      "|     Allegiant Air|\n",
      "|  Republic Airways|\n",
      "|      Endeavor Air|\n",
      "|         Envoy Air|\n",
      "|      PSA Airlines|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_visualization.select(\"OP_CARRIER\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12536/747146385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FL_DATE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FL_DATE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"yyyy-MM-dd\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "dataset = dataset.select(col(\"FL_DATE\"),to_date(col(\"FL_DATE\"),\"yyyy-MM-dd\").alias(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_visualization['Month'] = pd.DatetimeIndex(dataset_visualization['FL_DATE']).month\n",
    "dataset_visualization['Day'] = pd.DatetimeIndex(dataset_visualization['FL_DATE']).day\n",
    "dataset_visualization['Year'] = pd.DatetimeIndex(dataset_visualization['FL_DATE']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_visualization.tail(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the dataset for visualization using parquet dataformat , fast and low memory usage\n",
    "dataset_visualization.to_parquet(\"./Dataset/dataset_visualization.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After preparing a dataset for visualization , prepare the data for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop flight number - not needed\n",
    "dataset_visualization.drop('OP_CARRIER_FL_NUM', inplace=True, axis=1)\n",
    "\n",
    "#drop flight date - irrelevant\n",
    "dataset_visualization.drop('FL_DATE', inplace=True, axis=1)\n",
    "\n",
    "# drop diverted - feature irrelevant to problem \n",
    "dataset_visualization.drop('DIVERTED', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_visualization.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all rows having NA values\n",
    "dataset_ML = dataset_visualization.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_ML.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print insights on number of origin and dest \n",
    "categorical = [\"ORIGIN\",\"DEST\"] \n",
    "print(\"Number of departure locations : \",len(dataset_ML[categorical[0]].unique()))\n",
    "print(\"Number of destination locations : \",len(dataset_ML[categorical[1]].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the ORIGIN and DEST features , they have huge number of unique values , this means that :\n",
    "- using hot encoding for converting to numerical features will yield huge number of features which will lead to the curse of dimensionality \n",
    "- using label encoding will yield to only one feature , but the feature values will have great std deviation and labels will have different priority\n",
    "- so it would be better if we drop both\n",
    "\n",
    "### for the op_carrier :\n",
    "- different carriers may differ in plane services but irrelevant to our problem so it will be removed\n",
    "\n",
    "### FL_Date is only used for visualization so it will be removed , same for month day and year features\n",
    "- we could have made use of month feature because of its relation to a season in a year , but the data is only based on domestic flights of the US so it will biased to seasonality in the US only , model needs to generalize regardless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML=dataset_ML.drop('OP_CARRIER', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML=dataset_ML.drop('ORIGIN',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML=dataset_ML.drop('DEST',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML=dataset_ML.drop('Month',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML=dataset_ML.drop('Day',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML=dataset_ML.drop('Year',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_ML.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the dataset for visualization using parquet dataformat , fast and low memory usage\n",
    "dataset_ML.to_parquet(\"./Dataset/dataset_ML.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edfabf2557a0868ea416b237e6ea760256f23aebf1dc13eb828c839c8629c6ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
